---
title: "Modeling SWIRE"
author: "Imogen Holdsworth and Madalyn Young"
date: "2025-04-09"
output: html_document
---

```{r warning  = FALSE, collapse=TRUE }
pacman::p_load(tidyverse, scales, dplyr, corrr, janitor, tidyr, psych, readr, lubridate, rpart, rpart.plot, caret, C50, sf, maps, dbscan, geosphere, nnet, randomForest,readxl, tsibble, ggplot2, forecast, tseries, lme4, performance, yardstick, purr,lmerTest,tibble,purrr,pROC,Metrics)
```

# Data Load:

```{r warning = FALSE, collapse=TRUE}
CustomerProfileData <- read.csv("/Users/u0847758/Desktop/CAP/customer_profile.csv")  
TransactionalData <- read.csv("/Users/u0847758/Desktop/CAP/transactional_data (1).csv")
AddressZipData <- read.csv("/Users/u0847758/Desktop/CAP/customer_address_and_zip_mapping.csv")
DeliveryCostData <- read_excel("/Users/u0847758/Desktop/CAP/delivery_cost_data (1).xlsx")
```

## Data Cleaning - From Final
```{r address clean, warning = FALSE, collapse=TRUE}
#clean the address data
# Split the column
AddressZipData <- AddressZipData |>
  separate(full.address, into = c("ZIP", "City", "State Name", "State Short", 
                                  "County","Code", "Latitude", "Longitude"), sep = ",")

AddressZipData$Latitude <- as.numeric(AddressZipData$Latitude)

AddressZipData$Longitude <- as.numeric(AddressZipData$Longitude)
```


```{r transaction cleaning, warning = FALSE, collapse=TRUE}
TransactionalData$TRANSACTION_DATE <- mdy(TransactionalData$TRANSACTION_DATE)
  

TransactionalData <- TransactionalData %>% 
  mutate(Quarter_column = quarter(TRANSACTION_DATE), 
         Quarter_year = paste(Quarter_column, YEAR, sep = " "),
         MONTH = month(TRANSACTION_DATE)) %>% 
  select(-c(LOADED_CASES, DELIVERED_CASES, LOADED_GALLONS, DELIVERED_GALLONS))
```


```{r cust clean, collapse=FALSE}
#clean Customer Profile Data
  CustomerProfileData <-  CustomerProfileData %>% 
  mutate(
    Entity_ID = case_when(
      is.na(PRIMARY_GROUP_NUMBER) ~ CUSTOMER_NUMBER,  # If PRIMARY_GROUP_NUMBER is NA, use CUSTOMER_NUMBER
      TRUE ~ PRIMARY_GROUP_NUMBER),
    ON_BOARDING_DATE = mdy(ON_BOARDING_DATE),
    FIRST_DELIVERY_DATE = mdy(FIRST_DELIVERY_DATE),
    ON_BOARDING_YEAR = year(ON_BOARDING_DATE),
    FIRST_DELIVERY_YEAR = year(FIRST_DELIVERY_DATE))

char_col <- sapply(CustomerProfileData, is.character)
CustomerProfileData[char_col] <- lapply(CustomerProfileData[char_col], as.factor)

logical_cols <- sapply(CustomerProfileData, is.logical)
CustomerProfileData[logical_cols] <- lapply(CustomerProfileData[logical_cols], as.numeric)

#remove the customer where their on_boarding date was first delivery date was before the onboarding date (1 customer)
CustomerProfileData <- CustomerProfileData %>% 
  filter(FIRST_DELIVERY_DATE>=ON_BOARDING_DATE)
```

```{r aggregatecost, collapse=TRUE}
#Pivot wide the cost data
#aggregated  transaction data to join to customer table

# aggregate transaction data by customer_number and year
#sum the ordered cases and gallons by customer number and year
#this table is set up so each customer number has  two rows, one for 2023, one for 2024. Each column is sum of ordered cases/loaded cases. delivered cases in that year 
aggregated_cost <- TransactionalData |>
  group_by(CUSTOMER_NUMBER, YEAR) |>
  summarize(orderedCases = sum(ORDERED_CASES),
            orderedGallons = sum(ORDERED_GALLONS))



#The code pivots the database above to have one row per customer and a column for each cases/gallons ordered for each year
aggregated_cost_wide <- aggregated_cost |>
  pivot_wider(
    names_from = YEAR, 
    values_from = c(orderedCases, 
                    orderedGallons),
    names_sep = "_"
  )
```


```{r custloc join, collapse=TRUE}
CustomerProfile_Location <- CustomerProfileData %>% 
  left_join(AddressZipData, by = c("ZIP_CODE"="zip")) 
```

```{r locclust, collapse = TRUE}
#cluster the addresses and calculate the centroid for each cluster
##Multiple centroids
set.seed(123)

kmeans_result <- kmeans(CustomerProfile_Location[,c("Longitude", "Latitude")], centers = 4)

CustomerProfile_Location$cluster <- as.factor(kmeans_result$cluster)


centroids <- CustomerProfile_Location %>% 
  group_by(cluster) %>% 
  summarize(centroid_lon = mean(Longitude), centroid_lat = mean(Latitude))

```


```{r calc distance, collapse=TRUE}

haversine_distance <- function(lon1, lat1, lon2, lat2) {
  distHaversine(c(lon1, lat1), c(lon2,lat2))/1609.34 
}# converts meters to miles

#Join main customer data to the clusters created above
CustomerProfile_Location <- CustomerProfile_Location %>% 
  left_join(centroids, by = "cluster")


CustomerProfile_Location <- CustomerProfile_Location %>% 
  mutate(
    distance_to_centroid = mapply(haversine_distance, CustomerProfile_Location$Longitude, CustomerProfile_Location$Latitude, CustomerProfile_Location$centroid_lon, CustomerProfile_Location$centroid_lat)
  )

```

## Annual Customer No Retailer Dataset
```{r annualCust Filtering}
Annual_Customer_No_Retailer <- CustomerProfile_Location %>% 
  left_join(aggregated_cost_wide, by = "CUSTOMER_NUMBER") %>% 
  mutate(across(c(orderedCases_2023, orderedCases_2024, orderedGallons_2023, orderedGallons_2024), ~ replace_na(.x, 0)),
         total_ordered = (orderedCases_2024 + orderedGallons_2024 +orderedCases_2023 + orderedGallons_2023),
         total_ordered_2023 = (orderedCases_2023 + orderedGallons_2023),
         total_ordered_2024 = (orderedCases_2024 + orderedGallons_2024)) %>% 
  filter(!(year(FIRST_DELIVERY_DATE) == 2023 & orderedCases_2023 == 0 & orderedGallons_2023 == 0) &
    !(year(FIRST_DELIVERY_DATE) == 2024 & orderedCases_2024 == 0 & orderedGallons_2024 == 0)) %>% 
  filter(!(total_ordered_2023 ==0 & total_ordered_2024 == 0))

```


```{r Annual No Retailer Dataset, collapse=FALSE}
Annual_Customer_No_Retailer <- Annual_Customer_No_Retailer %>% 
  group_by(Entity_ID) %>% 
  summarize(FREQUENT_ORDER_TYPE = FREQUENT_ORDER_TYPE[which.max(tabulate(match(FREQUENT_ORDER_TYPE, unique(FREQUENT_ORDER_TYPE))))],
            COLD_DRINK_CHANNEL = first(COLD_DRINK_CHANNEL),
            TRADE_CHANNEL = first(TRADE_CHANNEL),
            SUB_TRADE_CHANNEL = first(SUB_TRADE_CHANNEL),
            FIRST_DELIVERY_DATE = min(FIRST_DELIVERY_DATE),
            FIRST_DELIVERY_YEAR = min(FIRST_DELIVERY_YEAR),
            ON_BOARDING_DATE = min(ON_BOARDING_DATE),
            ON_BOARDING_YEAR = min(ON_BOARDING_YEAR),
            customer_age = as.numeric(format(Sys.Date(), "%Y")) - ON_BOARDING_YEAR,
            numberOfOutlets = sum(case_when(is.na(PRIMARY_GROUP_NUMBER)~ 1,TRUE ~1)),
            LOCAL_MARKET_PARTNER = LOCAL_MARKET_PARTNER[which.max(tabulate(match(LOCAL_MARKET_PARTNER,unique(LOCAL_MARKET_PARTNER))))],
            CO2_CUSTOMER =  CO2_CUSTOMER[which.max(tabulate(match(CO2_CUSTOMER, unique(CO2_CUSTOMER))))],
            
            hasOrderedCases = as.integer(mean(case_when((orderedCases_2023 + orderedCases_2024)>0 ~1, TRUE ~ 0))>0,1,TRUE~0),
            
            propCases = sum(orderedCases_2023, orderedCases_2024)/ sum(total_ordered),
 
            zip_code =  first(ZIP), 
            
            city =  first(City),

            state =   
              first(`State Name`), 

            region = first(cluster),
             
            distance_from_centroid = first(distance_to_centroid),

            total_ordered_2023 = case_when(sum(total_ordered_2023)==0~1,TRUE~sum(total_ordered_2023)),
            total_ordered_2024 = sum(total_ordered_2024),
            percentChangeYOY = ((total_ordered_2024) - (total_ordered_2023))/(total_ordered_2023)) %>% 
  mutate(Binning_column = case_when(
    (total_ordered_2023 < 400 & total_ordered_2024 < 400) & percentChangeYOY < 0.10 ~ "low volume low growth",
         (total_ordered_2023 < 400 & total_ordered_2024 < 400) & percentChangeYOY >= 0.10 ~ "low volume high growth",
         (total_ordered_2023 > 400 & total_ordered_2024 > 400) & percentChangeYOY < 0.05 ~ "high volume low growth",
         (total_ordered_2023 > 400 & total_ordered_2024 > 400) & percentChangeYOY >=0.05 ~ "high volume high growth",
         (total_ordered_2023 >= 400 | total_ordered_2024 >= 400) & percentChangeYOY > 0 ~ "transtionary growing",
         (total_ordered_2023 >= 400 | total_ordered_2024 >= 400) & percentChangeYOY <= 0 ~ "transitionary declining" )) %>% 
  filter(numberOfOutlets == 1) 

```



```{r unaggragate transactions, collapse=TRUE}
aggregated_cost_by_month <- TransactionalData |>
  group_by(CUSTOMER_NUMBER, YEAR, Quarter_column, Quarter_year,MONTH) |>
  summarize(orderedCases = sum(ORDERED_CASES),
            orderedGallons = sum(ORDERED_GALLONS),
            totalOrdered = sum(ORDERED_CASES, ORDERED_GALLONS))
```


```{r unagjoinCust, collapes = TRUE}
UnaggregatedDates_Customer_No_Retailer <- CustomerProfile_Location %>% 
  left_join(aggregated_cost_by_month, by = "CUSTOMER_NUMBER") %>% 
   mutate(across(c(orderedCases, orderedGallons, totalOrdered), ~ replace_na(.x, 0))) 
  
```

```{r months, collapse=TRUE}
#create rows for each month
all_months <- crossing(
  CUSTOMER_NUMBER = unique(UnaggregatedDates_Customer_No_Retailer$CUSTOMER_NUMBER),
  YEAR = unique(UnaggregatedDates_Customer_No_Retailer$YEAR, na.rm = TRUE),
  MONTH = 1:12
) %>%
  mutate(
    Quarter_column = case_when(
      MONTH >= 1 & MONTH <= 3 ~ 1,
      MONTH >= 4 & MONTH <= 6 ~ 2,
      MONTH >= 7 & MONTH <= 9 ~ 3,
      TRUE ~ 4
    ),
    Quarter_year = paste(Quarter_column, YEAR, sep = " ")
  ) %>% filter(!is.na(YEAR) )

# First, create a customer reference dataset with one row per customer
customer_reference <- UnaggregatedDates_Customer_No_Retailer %>%
  group_by(CUSTOMER_NUMBER) %>%
  summarize(
    PRIMARY_GROUP_NUMBER = first(PRIMARY_GROUP_NUMBER),
    FREQUENT_ORDER_TYPE = first(FREQUENT_ORDER_TYPE),
    FIRST_DELIVERY_DATE = first(FIRST_DELIVERY_DATE),
    ON_BOARDING_DATE = first(ON_BOARDING_DATE),
    COLD_DRINK_CHANNEL = first(COLD_DRINK_CHANNEL),
    TRADE_CHANNEL = first(TRADE_CHANNEL),
    SUB_TRADE_CHANNEL = first(SUB_TRADE_CHANNEL),
    LOCAL_MARKET_PARTNER = first(LOCAL_MARKET_PARTNER),
    CO2_CUSTOMER = first(CO2_CUSTOMER),
    ZIP_CODE = first(ZIP_CODE),
    Entity_ID = first(Entity_ID),
    ON_BOARDING_YEAR = first(ON_BOARDING_YEAR),
    FIRST_DELIVERY_YEAR = first(FIRST_DELIVERY_YEAR),
    ZIP = first(ZIP),
    City = first(City),
    `State Name` = first(`State Name`),
    Latitude = first(Latitude),
    Longitude = first(Longitude),
    cluster = first(cluster),
    distance_to_centroid = first(distance_to_centroid)
  )

# Now join the transactions with all_months first, then join with customer reference

UnaggregatedDates_Customer_No_Retailer <- all_months %>%
  left_join(
    UnaggregatedDates_Customer_No_Retailer %>% 
      select(CUSTOMER_NUMBER, YEAR, MONTH, Quarter_column, Quarter_year, orderedCases, orderedGallons, totalOrdered),
    by = c("CUSTOMER_NUMBER", "YEAR", "MONTH")
  ) %>%
  mutate(across(c(orderedCases, orderedGallons, totalOrdered), ~ replace_na(.x, 0))) %>%
  # Join with the customer reference data
  left_join(customer_reference, by = "CUSTOMER_NUMBER")

```

## By Quarter Dataset
```{r By Quarter Data, collapse=FALSE}
BYQUARTER_Customer_No_Retailer <- UnaggregatedDates_Customer_No_Retailer %>% 
  filter(is.na(PRIMARY_GROUP_NUMBER)) %>% 
  group_by(Entity_ID, Quarter_year.x) %>% 
  reframe(
    FREQUENT_ORDER_TYPE = FREQUENT_ORDER_TYPE[which.max(tabulate(match(FREQUENT_ORDER_TYPE, unique(FREQUENT_ORDER_TYPE))))],
    COLD_DRINK_CHANNEL = first(COLD_DRINK_CHANNEL),
    TRADE_CHANNEL = first(TRADE_CHANNEL),
    SUB_TRADE_CHANNEL = first(SUB_TRADE_CHANNEL),
    FIRST_DELIVERY_DATE = min(FIRST_DELIVERY_DATE),
    FIRST_DELIVERY_YEAR = min(FIRST_DELIVERY_YEAR),
    ON_BOARDING_DATE = min(ON_BOARDING_DATE),
    ON_BOARDING_YEAR = min(ON_BOARDING_YEAR),
    customer_age = as.numeric(format(Sys.Date(), "%Y")) - ON_BOARDING_YEAR,
            
    LOCAL_MARKET_PARTNER = LOCAL_MARKET_PARTNER[which.max(tabulate(match(LOCAL_MARKET_PARTNER,unique(LOCAL_MARKET_PARTNER))))],
    CO2_CUSTOMER =  CO2_CUSTOMER[which.max(tabulate(match(CO2_CUSTOMER, unique(CO2_CUSTOMER))))],
    
    hasOrderedCases = as.integer(case_when((orderedCases)>0 ~1, TRUE ~ 0)),
            
    propCases = sum(orderedCases)/ sum(totalOrdered),
    
    zip_code =  first(ZIP), 
            
    city =  first(City),

    state =  first(`State Name`), 

    region = first(cluster),
             
    distance_from_centroid = first(distance_to_centroid),
    orderedCases = sum(orderedCases),
    orderedGallons = sum(orderedGallons),
    totalOrdered = sum(totalOrdered)) %>% 
   mutate(date = as.Date(paste0((as.integer(sub(" .*", "", Quarter_year.x)) - 1) * 3 + 1, 
                               "/1/", sub(".* ", "", Quarter_year.x)), 
                        format="%m/%d/%Y")) 
```

```{r edits to By Quarter, collapse = FALSE}
BYQUARTER_Customer_No_Retailer$quarter <- quarter(BYQUARTER_Customer_No_Retailer$date)
BYQUARTER_Customer_No_Retailer$quarter <- factor(paste0("Q", BYQUARTER_Customer_No_Retailer$quarter))
```


## Annual Customer Data Retailer Data
```{r}
Annual_Customer_Retailer <- CustomerProfile_Location %>% 
  left_join(aggregated_cost_wide, by = "CUSTOMER_NUMBER") %>% 
  mutate(across(c(orderedCases_2023, orderedCases_2024, orderedGallons_2023, orderedGallons_2024), ~ replace_na(.x, 0)),
         total_ordered = (orderedCases_2024 + orderedGallons_2024 +orderedCases_2023 + orderedGallons_2023),
         total_ordered_2023 = (orderedCases_2023 + orderedGallons_2023),
         total_ordered_2024 = (orderedCases_2024 + orderedGallons_2024)) %>% 
  filter(!(year(FIRST_DELIVERY_DATE) == 2023 & orderedCases_2023 == 0 & orderedGallons_2023 == 0) &
    !(year(FIRST_DELIVERY_DATE) == 2024 & orderedCases_2024 == 0 & orderedGallons_2024 == 0))

# Imogen update, filtering out the NA for primary group here, rather than filtering for more than one outlet 

Annual_Customer_Retailer <- Annual_Customer_Retailer |>
  filter(!is.na(PRIMARY_GROUP_NUMBER))


```

```{r}
Annual_Customer_Retailer <- Annual_Customer_Retailer %>% 
  group_by(Entity_ID) %>% 
    mutate(across(c(orderedCases_2023, orderedCases_2024, orderedGallons_2023, orderedGallons_2024), ~ replace_na(.x, 0)),
         total_ordered = (orderedCases_2024 + orderedGallons_2024 +orderedCases_2023 + orderedGallons_2023),
         total_ordered_2023 = (orderedCases_2023 + orderedGallons_2023),
         total_ordered_2024 = (orderedCases_2024 + orderedGallons_2024)) %>% 
  group_by(Entity_ID) %>% 
  summarize(FREQUENT_ORDER_TYPE = FREQUENT_ORDER_TYPE[which.max(tabulate(match(FREQUENT_ORDER_TYPE, unique(FREQUENT_ORDER_TYPE))))],
            COLD_DRINK_CHANNEL = first(COLD_DRINK_CHANNEL),
            TRADE_CHANNEL = first(TRADE_CHANNEL),
            SUB_TRADE_CHANNEL = first(SUB_TRADE_CHANNEL),
            FIRST_DELIVERY_DATE = min(FIRST_DELIVERY_DATE),
            FIRST_DELIVERY_YEAR = min(FIRST_DELIVERY_YEAR),
            ON_BOARDING_DATE = min(ON_BOARDING_DATE),
            ON_BOARDING_YEAR = min(ON_BOARDING_YEAR),
            customer_age = as.numeric(format(Sys.Date(), "%Y")) - ON_BOARDING_YEAR,
            
            LOCAL_MARKET_PARTNER = LOCAL_MARKET_PARTNER[which.max(tabulate(match(LOCAL_MARKET_PARTNER,unique(LOCAL_MARKET_PARTNER))))],
            CO2_CUSTOMER =  CO2_CUSTOMER[which.max(tabulate(match(CO2_CUSTOMER, unique(CO2_CUSTOMER))))],
            hasOutlet = first(case_when(is.na(PRIMARY_GROUP_NUMBER)~ 0,TRUE ~1)),
           # numberOfOutlets = sum(case_when(is.na(PRIMARY_GROUP_NUMBER)~ 1,TRUE ~1)), 
           # that code was not actually counting the number of distinct customer ids associated with an entity
           numberOfOutlets = n_distinct(CUSTOMER_NUMBER), # this should corrent that
            #wellPerformingOutlet = sum(case_when((orderedGallons_2023 + orderedCases_2023) >= 400 ~ 1, (orderedGallons_2024 + orderedCases_2024) >=400 ~ 1, TRUE ~ 0)),
           # that line needed to be changed too, because we are grouping by entity ID and we want to know within the entity ID group what number of customers a part of the same primary group are well performing - just wanted to use distinct to be sure 
           wellPerformingOutlet = n_distinct(CUSTOMER_NUMBER[(orderedCases_2023 + orderedGallons_2023 >= 400) |
  (orderedCases_2024 + orderedGallons_2024 >= 400)]),
            hasOrderedCases = as.integer(mean(case_when((orderedCases_2023 + orderedCases_2024)>0 ~1, TRUE ~ 0))>0,1,TRUE~0),
            
            propCases = sum(orderedCases_2023, orderedCases_2024)/ sum(total_ordered),
            
            GeoSpread = n_distinct(ZIP),
            most_common_zip = if_else(
              numberOfOutlets == 1,  # If only one location, take that ZIP
              first(ZIP),
              ZIP[which.max(tabulate(match(ZIP, unique(ZIP))))]), 
            largest_zip = if_else(
              numberOfOutlets == 1,
              first(ZIP),
              ZIP[which.max(total_ordered)]
            ),
            
            most_common_city = if_else(
              numberOfOutlets == 1,  # If only one location, take that ZIP
              first(City),
              City[which.max(tabulate(match(City, unique(City))))]), 
            largest_city = if_else(
              numberOfOutlets == 1,
              first(City),
              City[which.max(total_ordered)]
            ),
            
            most_common_state = if_else(
              numberOfOutlets == 1,  # If only one location, take that ZIP
              first(`State Name`),
              `State Name`[which.max(tabulate(match(`State Name`, unique(`State Name`))))]), 
            largest_state = if_else(
              numberOfOutlets == 1,
              first(`State Name`),
              `State Name`[which.max(total_ordered)]
            ),
            
            most_common_region = if_else(
              numberOfOutlets == 1,  # If only one location, take that ZIP
              first(cluster),
              cluster[which.max(tabulate(match(cluster, unique(cluster))))]), 
            largest_region = if_else(
              numberOfOutlets == 1,
              first(cluster),
              cluster[which.max(total_ordered)]
            ),
            
            most_common_distance = if_else(
              numberOfOutlets == 1,  # If only one location, take that ZIP
              first(distance_to_centroid),
              distance_to_centroid[which.max(tabulate(match(distance_to_centroid, unique(distance_to_centroid))))]), 
            
            largest_distance = if_else(
              numberOfOutlets == 1,
              first(distance_to_centroid),
              distance_to_centroid[which.max(total_ordered)]
            ),
            
                        
            avg_distance = if_else(
              numberOfOutlets == 1,
              first(distance_to_centroid),
              mean(distance_to_centroid)
            ),
            total_ordered_2023 = sum(total_ordered_2023),
            total_ordered_2024 = sum(total_ordered_2024),
            percentChangeYOY = ((total_ordered_2024) - (total_ordered_2023))/(total_ordered_2023))%>% 
  mutate(Binning_column = case_when(
    (total_ordered_2023 < 400 & total_ordered_2024 < 400) & percentChangeYOY < 0.10 ~ "low volume low growth",
         (total_ordered_2023 < 400 & total_ordered_2024 < 400) & percentChangeYOY > 0.10 ~ "low volume high growth",
         (total_ordered_2023 > 400 & total_ordered_2024 > 400) & percentChangeYOY < 0.05 ~ "high volume low growth",
         (total_ordered_2023 > 400 & total_ordered_2024 > 400) & percentChangeYOY > 0.05 ~ "high volume high growth",
         (total_ordered_2023 >= 400 | total_ordered_2024 >= 400) & percentChangeYOY > 0 ~ "transtionary growing ",
         (total_ordered_2023 >= 400 | total_ordered_2024 >= 400) & percentChangeYOY < 0 ~ "transitionary declining" )) 

#%>% 
  #filter(numberOfOutlets > 1) # commenting this out here as i filtered for where primary group is NA
```


# Non Retailer modeling:
## Model 1
Linear regression using quarter as a factor predictor variable. 

This model was to identify significance and impact of each quarter. Though it did not improve R2 very well, I started to see impacts of Q3
```{r model1, collapse=FALSE}
model1 <- lm(totalOrdered ~ FREQUENT_ORDER_TYPE + COLD_DRINK_CHANNEL + TRADE_CHANNEL + customer_age + LOCAL_MARKET_PARTNER + CO2_CUSTOMER + propCases + distance_from_centroid + quarter , data = BYQUARTER_Customer_No_Retailer)


summary(model1)
```


## Model 2
This is my Arima model by quarter
```{r convert Quarter to TS object, collapse=FALSE}
ts_dataQ <- BYQUARTER_Customer_No_Retailer %>% 
  group_by(date) %>%
  summarize(totalOrdered = sum(totalOrdered, na.rm = TRUE)) %>%
  arrange(date) %>%  # Ensure data is ordered by time
  pull(totalOrdered) %>%  # Extract the numeric vector
  ts(start = c(year(min(BYQUARTER_Customer_No_Retailer$date)), month(min(BYQUARTER_Customer_No_Retailer$date))), 
     frequency = 4) 
```

```{r}
autoplot(ts_dataQ)
```


```{r test for stationary, collapse=FALSE}
adf.test(ts_dataQ)
```

data is stationary and there is no need for differencing!!! this means that the data does not have trends or seasonality that would make it difficult to predict. What I clearly see from the graph. there is one quarter each year where ordering takes place and we can predict that

```{r build the arima, collapse=FALSE}

#these are the tests to build my arima model
acf(ts_dataQ) # 1 significant spike q= 1
pacf(ts_dataQ) # 0 significant spike p= 0

#Arima
QArima <- arima(ts_dataQ, order = c(0,0,1))

summary(QArima)

```
**for the specified arima**
1. Coefficients:
ma1 (-0.9980): This is the first-order moving average coefficient. A value close to -1 suggests that the series has strong negative autocorrelation at lag 1, meaning that an increase in one period tends to be followed by a decrease in the next.

Intercept (4,369,738.19): This represents the mean level of the series (assuming no differencing was applied).

2. Standard Errors (s.e.):
ma1 standard error (0.4149): Measures the uncertainty around the MA(1) estimate.

Intercept standard error (48,231.29): Suggests that the intercept estimate has a relatively small uncertainty compared to its magnitude.

3. Model Fit Metrics:
sigma² (1.398e+11): This is the estimated variance of the residuals.

Log-likelihood (-115.1): Higher values (less negative) suggest a better fit.

AIC (236.19): A lower AIC indicates a better model fit relative to others.

4. Training Set Error Measures:
ME (-86,206.46): Mean error, showing a slight underestimation bias.

RMSE (373,931.1): Measures how much the predicted values deviate from actual values on average.

MAE (346,158.9): Mean absolute error, showing the typical size of forecast errors.

MPE (-2.70%): Mean percentage error, indicating the direction of bias (slight underestimation).

MAPE (8.11%): Mean absolute percentage error, meaning your model's predictions are, on average, 8.11% off.

MASE (0.5429): Mean absolute scaled error; values below 1 suggest better performance than a naive forecast.

ACF1 (0.1830): Autocorrelation of residuals at lag 1. A low value suggests that residuals are fairly uncorrelated (which is good).

Interpretation:
Your MA(1) coefficient is close to -1, suggesting strong negative autocorrelation.

The AIC is reasonable, though you might want to compare it with other models (e.g., ARIMA(1,0,1), ARIMA(0,1,1)).

The MAPE of 8.11% indicates a fairly good predictive performance.

The residual autocorrelation (ACF1 = 0.183) is low, which means the model does not leave much pattern in the residuals.

## Model 3
This is an auto arima to compare to the arima I build manually above
```{r second arima for comp, collapse=FALSE}
#the above model is better
QArimaAuto <- auto.arima(ts_dataQ)
summary(QArimaAuto)
```


## Model 4
This model I tried to create as a way to include both quarter and the binning column to see how it would help a linear regression model

R2 is 0.22, better than a lot of models I had built by this point

```{r join to get bin, collapse=TRUE}
BYQUARTER_Customer_No_Retailer <- BYQUARTER_Customer_No_Retailer %>% 
  left_join(Annual_Customer_No_Retailer %>% select(Entity_ID, Binning_column), by = "Entity_ID")
```


```{r}
model4 <- lm((totalOrdered) ~ FREQUENT_ORDER_TYPE + COLD_DRINK_CHANNEL + TRADE_CHANNEL + customer_age + LOCAL_MARKET_PARTNER*CO2_CUSTOMER + propCases + distance_from_centroid + quarter +Binning_column , data = BYQUARTER_Customer_No_Retailer)


summary(model4)
```


## Model 5
This model is an adjustment of the top by logging total orders. I did this to account for the skewedness of total orders and help the predicitability of the model that way. This was successful. This was my best model before moving to MLM
```{r}
model5 <- lm(log(totalOrdered) ~ FREQUENT_ORDER_TYPE + COLD_DRINK_CHANNEL + TRADE_CHANNEL + customer_age + LOCAL_MARKET_PARTNER*CO2_CUSTOMER + propCases + distance_from_centroid + quarter +Binning_column , data = BYQUARTER_Customer_No_Retailer)

summary(model5)
```


***I did modeling in the bins, just regressions, a lot of the same as well. All were not well performing. The best performing models were for well performing customers, confirming the issue I had that high volume customers were driving predictability and R2 of my main consolidated models.**

**Let me know if you want me to add any of these for our swire submission**

## Model 6
This is my final MLM model. I did a handful of others, mostly I had more factor variables in my model. not many were significant and when I tried cross validating it would error out due to mismatched levels. I also was not including percent change until this model. I also tried mlm's with customers ordering less than 400 and saw poorer performance

```{r}
Annual_Customer_No_Retailer$Binning_column <- as.factor(Annual_Customer_No_Retailer$Binning_column)

Annual_Customer_No_Retailer <- Annual_Customer_No_Retailer %>% 
  filter(Entity_ID != 4445)


set.seed(123)

# you enter the proportion for the split here. I'd suggest .8
inTrainMLM3<- createDataPartition(Annual_Customer_No_Retailer$total_ordered_2024, p=.8, list=FALSE)

# use the row indexes from line 87 to create the 2 sets.
# train includes the index, test excludes the index.

train_setMLM3 <- Annual_Customer_No_Retailer[inTrainMLM3,]
test_setMLM3 <- Annual_Customer_No_Retailer[-inTrainMLM3,]

```


```{r}
MLMTrain3 <- lmer(total_ordered_2024~customer_age + LOCAL_MARKET_PARTNER + CO2_CUSTOMER + propCases + distance_from_centroid + total_ordered_2023 + percentChangeYOY +  (1|Binning_column), data = train_setMLM3)

```

```{r}
summary(MLMTrain3)
```

```{r predictions}

test_setMLM3$predictions <- pmax(predict(MLMTrain3, newdata =test_setMLM3, allow.new.levels = TRUE),0)

```


```{r rmse}

#this is RMSE 
sqrt(mean((test_setMLM3$total_ordered_2024 - test_setMLM3$predictions)^2))

```

```{r r2}
rsq <- cor(test_setMLM3$total_ordered_2024, test_setMLM3$predictions)^2

print(rsq)

r2(MLMTrain3)

ranef(MLMTrain3)$Binning_column
```


```{r}
test_setMLM3 %>% 
  filter(total_ordered_2024<=10000) %>% 
ggplot(aes(x = total_ordered_2024, y = predictions)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(x = "Actual", y = "Predicted") +
  scale_y_continuous(labels = label_number(scale = 1e-3, suffix = "K"))+
  scale_x_continuous(labels = label_number(scale = 1e-3, suffix = "K"))+
  theme_minimal()+
   theme( 
    panel.grid = element_blank(), 
    axis.line = element_line(color = "black"),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA)) 
```

```{r}
car::vif(MLMTrain3)
```
vif of 5 means there is no signficant multicollinearity.

I guess what this means is that orders and % change are so variable that the bins themselves dont capture the correlation very heavily 

"This means keeping both variables in the model could still be informative—one capturing broad customer segmentation and the other providing a more continuous measure of change. Sounds like a solid approach!"

***Cross Validation of main MLM Model***

Just as a note, the cross validation is how I identified customer 4445 needed to be filtered out
```{r}
# First, ensure all factors have consistent levels throughout your dataset
factor_vars <- c("FREQUENT_ORDER_TYPE", "COLD_DRINK_CHANNEL", "TRADE_CHANNEL", "Binning_column")

for(var in factor_vars) {
  if(is.factor(Annual_Customer_No_Retailer[[var]]) || is.character(Annual_Customer_No_Retailer[[var]])) {
    Annual_Customer_No_Retailer[[var]] <- factor(Annual_Customer_No_Retailer[[var]])
    print(paste("Factor", var, "has", length(levels(Annual_Customer_No_Retailer[[var]])), "levels"))
  }
}

# Store original factor levels
original_levels <- list()
for(var in factor_vars) {
  if(is.factor(Annual_Customer_No_Retailer[[var]])) {
    original_levels[[var]] <- levels(Annual_Customer_No_Retailer[[var]])
  }
}
```


```{r}
set.seed(1234)
folds <- createFolds(unique(Annual_Customer_No_Retailer$total_ordered_2024), k = 5, list = TRUE, returnTrain = FALSE)

# Initialize storage for performance metrics
cv_rmse <- numeric(length(folds))
cv_mae <- numeric(length(folds))
cv_r2 <- numeric(length(folds))

```


```{r}
for(i in seq_along(folds)) {
  # Create test set indices
  
  test_indices <- folds[[i]]
  
  # Train and test sets
  train_data <- Annual_Customer_No_Retailer[-test_indices, ]
  test_data <- Annual_Customer_No_Retailer[test_indices, ]
  
  # IMPORTANT: Ensure test data has same factor levels as train data
  for(var in factor_vars) {
    if(is.factor(train_data[[var]])) {
      # Set levels for training data to be all original levels
      levels(train_data[[var]]) <- original_levels[[var]]
      
      # Ensure test data has same levels
      test_data[[var]] <- factor(test_data[[var]], levels = original_levels[[var]])
    }
  }
  
  # Fit model - wrapped in tryCatch to handle any remaining errors gracefully
  mlm_model <- tryCatch({
    lmer(total_ordered_2024 ~   
         customer_age + LOCAL_MARKET_PARTNER + 
         CO2_CUSTOMER + propCases + distance_from_centroid + 
         total_ordered_2023 + (1|Binning_column), 
         data = train_data)
  }, error = function(e) {
    message("Error in fold ", i, ": ", e$message)
    return(NULL)
  })
  
  # Skip this fold if model fitting failed
  if(is.null(mlm_model)) {
    cv_rmse[i] <- NA
    cv_mae[i] <- NA
    next
  }
  
  # Make predictions - with error handling
  predictions <- tryCatch({
    predict(mlm_model, newdata = test_data, allow.new.levels = TRUE)
  }, error = function(e) {
    message("Prediction error in fold ", i, ": ", e$message)
    return(NULL)
  })
  
  # Skip metrics calculation if prediction failed
  if(is.null(predictions)) {
    cv_rmse[i] <- NA
    cv_mae[i] <- NA
    next
  }
  
  # Calculate performance metrics
  cv_rmse[i] <- sqrt(mean((test_data$total_ordered_2024 - predictions)^2, na.rm = TRUE))
  cv_mae[i] <- mean(abs(test_data$total_ordered_2024 - predictions), na.rm = TRUE)
  ss_res <- sum((test_data$total_ordered_2024-predictions)^2, na.rm = TRUE)
  ss_tot <- sum((test_data$total_ordered_2024-mean(test_data$total_ordered_2024, na.rm = TRUE))^2, na.rm = TRUE)
  cv_r2[i] <- 1 - (ss_res/ss_tot)
  
  cat("Fold", i, "completed. RMSE:", cv_rmse[i], "MAE:", cv_mae[i], "\n")
}

# Average performance across folds (ignoring NA values)
mean_rmse <- mean(cv_rmse, na.rm = TRUE)

mean_mae <- mean(cv_mae, na.rm = TRUE)
mean_r2 <- mean(cv_r2, na.rm = TRUE)

cat("\nCross-validation results:\n")
cat("Mean RMSE:", mean_rmse, "\n")
cat("Mean MAE:", mean_mae, "\n")
cat("Individual fold RMSEs:", cv_rmse, "\n")
cat("Individual fold RMSEs:", cv_mae, "\n")
cat("Mean R-squared:", mean_r2, "\n")
cat("Individual fold R-squareds:", cv_r2, "\n")


```
***Predict 2025***
```{r}
ACNR <- Annual_Customer_No_Retailer

final_model <- lmer(total_ordered_2024 ~   
         customer_age + LOCAL_MARKET_PARTNER + 
         CO2_CUSTOMER + propCases + distance_from_centroid + 
         total_ordered_2023 + (1|Binning_column), 
         data = ACNR)

ACNR2025 <- ACNR %>% 
   mutate(total_ordered_2023 = total_ordered_2024,
          customer_age = customer_age +1) %>% 
  select(-total_ordered_2024)


ACNR2025$predictions_2025 <- predict(final_model, newdata = ACNR2025)

ACNR2025$predictions_2025 <- ACNR2025$predictions_2025
```


```{r}
bin_summary <- ACNR2025 %>% 
  mutate(over_400_in_2025 = predictions_2025 > 400) %>% 
  group_by(Binning_column) %>% 
  summarize(
    total_customers = n(),
    ccustomers_over_400_2025 = sum(over_400_in_2025, na.rm = TRUE)  )

print(bin_summary)
```


# Retailer Modeling:

Outlet customers are distinguished from non outlet customers:

## Decision Tree 1
```{r}

# the "main" data that was used previously : all customer data profile joined with transaction using the Customer Profile Location Data created above.

Customer_Full_Data <- CustomerProfile_Location %>% 
  left_join(aggregated_cost_wide, by = "CUSTOMER_NUMBER") %>% 
  mutate(across(c(orderedCases_2023, orderedCases_2024, orderedGallons_2023, orderedGallons_2024), ~ replace_na(.x, 0)),
         total_ordered = (orderedCases_2024 + orderedGallons_2024 +orderedCases_2023 + orderedGallons_2023),
         total_ordered_2023 = (orderedCases_2023 + orderedGallons_2023),
         total_ordered_2024 = (orderedCases_2024 + orderedGallons_2024)) %>% 
  filter(!(year(FIRST_DELIVERY_DATE) == 2023 & orderedCases_2023 == 0 & orderedGallons_2023 == 0) &
    !(year(FIRST_DELIVERY_DATE) == 2024 & orderedCases_2024 == 0 & orderedGallons_2024 == 0)) %>% 
  filter(!(total_ordered_2023 ==0 & total_ordered_2024 == 0))

Customer_Full_Data <- Customer_Full_Data %>%
  mutate(has_outlet = if_else(!is.na(PRIMARY_GROUP_NUMBER), 1, 0))

outlet_counts <- Customer_Full_Data %>%
  group_by(Entity_ID) %>%
  summarise(number_of_outlets = n_distinct(CUSTOMER_NUMBER), .groups = "drop")

Customer_Full_Data <- Customer_Full_Data %>%
  left_join(outlet_counts, by = "Entity_ID")


# this should not have any issues running on the group set as it is using the same defined variables from above. 

Customer_Full_Data <- Customer_Full_Data |>
  mutate(
    total_ordered = orderedCases_2023 + orderedGallons_2023 + orderedCases_2024 + orderedGallons_2024,
    high_order_volume = if_else(total_ordered >= 400, "High", "Low")
  )

set.seed(123)
train_index <- sample(1:nrow(Customer_Full_Data), 0.7 * nrow(Customer_Full_Data))
train_data <- Customer_Full_Data[train_index, ]
test_data <- Customer_Full_Data[-train_index, ]
predictors <- c("has_outlet", "number_of_outlets", "CO2_CUSTOMER", "LOCAL_MARKET_PARTNER")
target <- "high_order_volume"
test_x <- test_data[, predictors]
test_y <- as.factor(test_data[[target]])

tree_model <- C5.0(
  x = train_data[, predictors],
  y = as.factor(train_data[[target]])
)

summary(tree_model)

pred <- predict(tree_model, newdata = test_x)

confusionMatrix(pred, as.factor(test_y))

C5imp(tree_model, metric = "usage")
```

Using a decision tree, we found that customers who belong to a retailer group (as indicated by has_outlet) are significantly more likely to be high-volume purchasers. The number of outlets in a retailer group also contributes, although to a lesser degree. The decsion tree also confirms the LMP groups to be high ordering individuals 

## Modeling Outlet Count Importance

retilers with small number of outlets but high order volumes, indicate that likley outlet count is not as important of volume per outelt. 
```{r}

mighty_minis <- Annual_Customer_Retailer |>
  filter(numberOfOutlets <= 3, total_ordered_2024 >= 400) |>
  mutate(segment = "Mighty Minis")

low_performers <- Annual_Customer_Retailer |>
  filter(numberOfOutlets <= 3, total_ordered_2024 < 400) |>
  mutate(segment = "Low Performers")

combined <- bind_rows(mighty_minis, low_performers)

comparison_summary <- combined|>
  group_by(segment) |>
  summarise(
    n_customers = n(),
    avg_order_2023 = round(mean(total_ordered_2023, na.rm = TRUE), 1),
    avg_order_2024 = round(mean(total_ordered_2024, na.rm = TRUE), 1),
    avg_geo_spread = round(mean(GeoSpread, na.rm = TRUE), 2),
    avg_outlets = round(mean(numberOfOutlets, na.rm = TRUE), 2),
    avg_well_performing = round(mean(wellPerformingOutlet, na.rm = TRUE), 2),
    avg_customer_age = round(mean(customer_age, na.rm = TRUE), 1),
    pct_LMP = round(mean(LOCAL_MARKET_PARTNER, na.rm = TRUE) * 100, 1),
    pct_CO2 = round(mean(CO2_CUSTOMER, na.rm = TRUE) * 100, 1)
  )

comparison_summary %>%
  kable(format = "html", caption = "Comparison of Mighty Minis vs Low-Performing Small Retailers") |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

for the same range of outlets, these mighty minis have higher 2023 order volume, have a higher proportion of well performing outlets, have larger geo spread and are slightly older. 

outlet count does not equal success, retail size does not mean order volume will be high, this is identifying that individual customer performance will be important to understand within larger retail groups. 

## Modeling: logistic regression

with modeling can we prove that past outlet performance predicts future order volume amounts, if we want to use current order volumes as a feature in understanding swires customers we need to see if their prior order perfomrnace is strongly associated with future order performance.

We also want to explore if having at least one well-performing outlet in 2023 is associated with a significantly higher likelihood of crossing the 400-gallon threshold in 2024

```{r}

Annual_Customer_Retailer <- Annual_Customer_Retailer |>
  mutate(is_above_400_2024 = if_else(total_ordered_2024 >= 400, 1, 0))

logit_model <- glm(
  is_above_400_2024 ~ wellPerformingOutlet + total_ordered_2023 +
    numberOfOutlets + customer_age + GeoSpread + CO2_CUSTOMER + LOCAL_MARKET_PARTNER,
  data = Annual_Customer_Retailer,
  family = binomial
)

summary(logit_model)

exp(coef(logit_model))

exp(3.1900584)
```

Well perfoming outlet and prior order volume are incrediblly statistically significant. Customers with even one well-performing outlet are 24x more likely to exceed 400 gallons in the following year. Outlet-level performance is the one of the strongest growth predictors as well as considering prior order volume.

verify that models performance with test train split 

```{r}

set.seed(123)
split_index <- sample(1:nrow(Annual_Customer_Retailer), 0.7 * nrow(Annual_Customer_Retailer))
train_data <- Annual_Customer_Retailer[split_index, ]
test_data  <- Annual_Customer_Retailer[-split_index, ]
target <- "is_above_400_2024"
test_x <- test_data %>% select(-all_of(target))
test_y <- test_data[[target]]



glm_1 <- glm(
  is_above_400_2024 ~ wellPerformingOutlet + total_ordered_2023 +
    numberOfOutlets + customer_age + GeoSpread + CO2_CUSTOMER + LOCAL_MARKET_PARTNER,
  data = train_data,
  family = "binomial"
)

predicted_probs <- predict(glm_1, newdata = test_x, type = "response")

predicted_class <- ifelse(predicted_probs >= 0.5, 1, 0)

# Confusion Matrix
table(Predicted = predicted_class, Actual = test_y)

# Accuracy
mean(predicted_class == test_y)

summary(glm_1)

# had to use explicit arguments. 
roc_obj <- pROC::roc(response = test_y, predictor = predicted_probs)
pROC::auc(roc_obj)

```


With an AUC of 0.97, we can be highly confident in its ability to distinguish growth-ready customers from those unlikely to expand. well performing outlet was the biggest signal of future growth

this also helps us like further prove that retail customers should be seperate bc outlet information is not something available across all customers.

now we can use this to develop a kind of scoring for the customer - 


cross validation for this model, as well as determining best thresholds:
```{r}

# factor target

Annual_Customer_Retailer$growth_2024 <- ifelse(Annual_Customer_Retailer$is_above_400_2024 == 1, "above", "below")
Annual_Customer_Retailer$growth_2024 <- as.factor(Annual_Customer_Retailer$growth_2024)

# cross-validation
set.seed(123)
ctrl <- trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary)

# logistic regression CV
cv_model <- train(
  growth_2024 ~ wellPerformingOutlet + total_ordered_2023 +
    numberOfOutlets + customer_age + GeoSpread + CO2_CUSTOMER + LOCAL_MARKET_PARTNER,
  data = Annual_Customer_Retailer,
  method = "glm",
  family = "binomial",
  trControl = ctrl,
  metric = "ROC"
)


roc_obj <- pROC::roc(response = test_y, predictor = predicted_probs)
pROC::auc(roc_obj)

# best threshold finding for increased sensitivity balanced with specificity  
thresholds <- data.frame(
  threshold = roc_obj$thresholds,
  sensitivity = roc_obj$sensitivities,
  specificity = roc_obj$specificities
)

# Find the threshold with maximum sensitivity
best_sens <- thresholds[which.max(thresholds$sensitivity), ]
print(best_sens)


best_balanced <- thresholds |>
  filter(sensitivity >= 0.95, specificity >= 0.80) |>
  slice_max(order_by = specificity, n = 1)

print(best_balanced)


# new optimal threshhold for the model: 0. 4583473


# Use the optimal threshold from ROC analysis
optimal_threshold <- 0.4583473
predicted_class_opt <- ifelse(predicted_probs >= optimal_threshold, 1, 0)

# Confusion matrix and accuracy at new threshold
conf_matrix_opt <- table(Predicted = predicted_class_opt, Actual = test_y)
accuracy_opt <- mean(predicted_class_opt == test_y)

# Print results
print(conf_matrix_opt)
cat("New Accuracy:", accuracy_opt, "\n")



# new CV at the threshold 

set.seed(123)

# Create 5 folds
folds <- createFolds(Annual_Customer_Retailer$is_above_400_2024, k = 5)

# Set custom threshold
custom_thresh <- 0.4583473

cv_results <- data.frame(ROC = numeric(), Sens = numeric(), Spec = numeric())

for (i in 1:5) {
  # Split data
  test_idx <- folds[[i]]
  train_fold <- Annual_Customer_Retailer[-test_idx, ]
  test_fold  <- Annual_Customer_Retailer[test_idx, ]
  
  # Train logistic model
  glm_cv <- glm(
    is_above_400_2024 ~ wellPerformingOutlet + total_ordered_2023 +
      numberOfOutlets + customer_age + GeoSpread + CO2_CUSTOMER + LOCAL_MARKET_PARTNER,
    data = train_fold,
    family = "binomial"
  )
  
  # Predict probabilities
  probs <- predict(glm_cv, newdata = test_fold, type = "response")
  
  # Classify using your custom threshold
  preds <- ifelse(probs >= custom_thresh, 1, 0)
  
  # Evaluate
  roc <- pROC::roc(test_fold$is_above_400_2024, probs)
  sens <- sensitivity(as.factor(preds), as.factor(test_fold$is_above_400_2024), positive = "1")
  spec <- specificity(as.factor(preds), as.factor(test_fold$is_above_400_2024), negative = "0")
  
  # Store results
  cv_results <- rbind(cv_results, data.frame(
    ROC = pROC::auc(roc),
    Sens = sens,
    Spec = spec
  ))
}

# View results
summary(cv_results)
colMeans(cv_results)

```

To validate the strength of our retail customer growth model, we performed 5-fold cross-validation using a custom threshold optimized for high sensitivity. The model consistently achieved an AUC of ~0.97 and identified nearly 97% of growth-ready customers while maintaining high specificity. This gives us confidence in our ability to proactively identify and prioritize future high-performing accounts.


predict  with glm model: 
```{r}

glm_final <- glm(
  is_above_400_2024 ~ wellPerformingOutlet + total_ordered_2023 +
    numberOfOutlets + customer_age + GeoSpread + CO2_CUSTOMER + LOCAL_MARKET_PARTNER,
  data = Annual_Customer_Retailer,
  family = "binomial"
)

# predict a 2025 over under 400 using the new threhsold.
Annual_Customer_Retailer <- Annual_Customer_Retailer %>%
  mutate(
    growth_score_2025 = predict(glm_final, type = "response"),
    predicted_over_400_2025 = if_else(growth_score_2025 >= 0.458, 1, 0)  # Using best threshold
  )

```


```{r}
summary_table <- Annual_Customer_Retailer |>
  group_by(Binning_column) |>
  summarise(
    n_customers = n(),
    above_400_2024 = sum(is_above_400_2024 == 1, na.rm = TRUE),
    predicted_above_400_2025 = sum(predicted_over_400_2025 == 1, na.rm = TRUE),
    pct_above_400_2024 = round(mean(is_above_400_2024 == 1, na.rm = TRUE) * 100, 1),
    pct_predicted_above_400_2025 = round(mean(predicted_over_400_2025 == 1, na.rm = TRUE) * 100, 1)
  ) %>%
  arrange(desc(pct_predicted_above_400_2025))

print(summary_table)
```

comparing model performance when we remove reliable performers from the data: 

```{r}

# start with moving over 1000
Annual_Customer_Retailer <- Annual_Customer_Retailer |>
  mutate(Binning_column = case_when(
    (total_ordered_2023 < 400 & total_ordered_2024 < 400) & percentChangeYOY < 0.10 ~ "low volume low growth",
    (total_ordered_2023 < 400 & total_ordered_2024 < 400) & percentChangeYOY > 0.10 ~ "low volume high growth",
    (total_ordered_2023 >= 1000 & total_ordered_2024 >= 1000 ) & percentChangeYOY < 0.05  ~ "high volume low growth",
    (total_ordered_2023 >= 1000 & total_ordered_2024 >= 1000 ) & percentChangeYOY > 0.05  ~ "high volume high growth",
    (total_ordered_2023 > 400 | total_ordered_2024 > 400) & percentChangeYOY > 0 ~ "transtionary growing",
    (total_ordered_2023 >= 400 | total_ordered_2024 >= 400) & percentChangeYOY < 0 ~ "transitionary declining" ))
    
  
Annual_Customer_Retailer <- Annual_Customer_Retailer |>
  mutate(
    risk_reward_segment = case_when(
      Binning_column %in% c("high volume low growth" , "high volume high growth") ~ "Reliable Performers",
      Binning_column == "low volume low growth" ~ "Low Risk / Low Reward",
      Binning_column == "low volume high growth" ~ "High Risk / High Reward",
      Binning_column == "transtionary growing" ~ "Emerging Opportunity",  # had issues here, realized thers a space on the bin name
      Binning_column == "transitionary declining" ~ "Intervention Needed",
      TRUE ~ "Unclassified"
    )
  )

# now i want to filter out the reliable guys, for those with 1000 in both years 

non_reliable <- Annual_Customer_Retailer |>
  filter(!(Binning_column %in% c("high volume low growth", "high volume high growth")))

non_reliable <- non_reliable |>
  mutate(is_above_400_2024 = ifelse(total_ordered_2024 >= 400, 1, 0))

non_reliable <- non_reliable |>
  select(-starts_with("growth_score_2025"),
         -starts_with("predicted_over_400_2025"))

# no we will retrain to find 2024 from 2023 to see how good the model is 
set.seed(2024)
train_idx <- sample(1:nrow(non_reliable), 0.7 * nrow(non_reliable))
train_data <- non_reliable[train_idx, ]
test_data  <- non_reliable[-train_idx, ]
test_x <- test_data %>% select(-is_above_400_2024)
test_y <- test_data$is_above_400_2024


glm_model_no_reliable <- glm(
  is_above_400_2024 ~ total_ordered_2023 + numberOfOutlets + 
    wellPerformingOutlet + customer_age + GeoSpread + 
    CO2_CUSTOMER + LOCAL_MARKET_PARTNER,
  data = train_data,
  family = binomial
)

predicted_probs <- predict(glm_model_no_reliable, newdata = test_x, type = "response")
pred_class <- ifelse(predicted_probs >= 0.458, 1, 0)

# Confusion matrix & accuracy
table(Predicted = pred_class, Actual = test_y)
mean(pred_class == test_y)

roc_obj <- pROC::roc(response = test_y, predictor = predicted_probs)
pROC::auc(roc_obj)

```

now AUC is only 91.8 for finding 24 from 2023. with out the high reliable peeps in the mix. 

now just predicting 2025 for this "non reliable" group

```{r}
# predict 2025 for this segmenet, to see if the removed noise from the super high orders helps us in our understandings 

# 2025 probabilities for non-reliable customers
non_reliable$predicted_growth_prob_2025 <- predict(glm_model_no_reliable, newdata = non_reliable, type = "response")

# Simulate 2025 threshold crossing
set.seed(2025)
non_reliable$is_above_400_2025 <- rbinom(
  n = nrow(non_reliable),
  size = 1,
  prob = non_reliable$predicted_growth_prob_2025
)

# Prep data for plotting
non_reliable_summary <- non_reliable |>
  summarise(
    Above_400_2024 = mean(is_above_400_2024),
    Above_400_2025 = mean(is_above_400_2025)
  ) %>%
  pivot_longer(cols = everything(), names_to = "Year", values_to = "Proportion")

# Plot
ggplot(non_reliable_summary, aes(x = Year, y = Proportion, fill = Year)) +
  geom_bar(stat = "identity", width = 0.5) +
  geom_text(aes(label = scales::percent(Proportion, accuracy = 1)), vjust = -0.5) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
  labs(
    title = "Non-Reliable Customers: % Above 400 Gallons",
    x = NULL,
    y = "Proportion"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

table(
  `2024` = non_reliable$is_above_400_2024,
  `2025_predicted` = non_reliable$is_above_400_2025
)
```

57 individual retailers, but about 450 individual customers within thsoe retailers, transtionary growing segments had the largest amount of custoemrs anticipated to be above threshold in 2025

We tested two approaches to forecasting 2025 volume, A logistic regression model trained on 2023 and 2024 performance and outlet data, and a rule-based YoY simulation with noise to mimic real-world volatility.The results aligned 99.4% of the time, which gave us confidence in the predictive value of our model. 

Our analysis strongly supports the hypothesis that volume per outlet and outlet performance are better predictors of future customer growth than total volume or outlet count alone. In a logistic regression model predicting whether customers surpassed the 400-gallon threshold in 2024, the presence of well-performing outlets was by far the most significant indicator — increasing the odds of growth by nearly 29 times, even when controlling for overall volume and number of outlets. While total gallons and outlet count contributed meaningfully, their predictive power was far less pronounced. These results validate our strategy of emphasizing outlet-level behavior when evaluating customer potential, reinforcing that not all volume is created equal — where and how customers order matters more than how much.


## Modeling: segment analysis

Reliable Performers and Emerging Opportunities have significantly higher average volume per outlet than other groups, and justify direct routing investment.


```{r}

Annual_Customer_Retailer <- Annual_Customer_Retailer |>
  mutate(volume_per_outlet24 = total_ordered_2024 / numberOfOutlets)

Annual_Customer_Retailer |>
  group_by(Binning_column) |>
  summarise(
    avg_volume_per_outlet = mean(volume_per_outlet24),
    median_volume = median(volume_per_outlet24),
    count = n()
  ) %>%
  arrange(desc(avg_volume_per_outlet))

```

The data shows strong variation in average volume per outlet across customer segments:

## MLM Modeling : Retialers

start with breif reformatting of the data to allow for individual customer level analysis within retail groups
 
```{r warning = FALSE, collapse=TRUE}
CustomerProfileData <- read.csv("/Users/u0847758/Desktop/CAP/customer_profile.csv")  
TransactionalData <- read.csv("/Users/u0847758/Desktop/CAP/transactional_data (1).csv")
AddressZipData <- read.csv("/Users/u0847758/Desktop/CAP/customer_address_and_zip_mapping.csv")
DeliveryCostData <- read_excel("/Users/u0847758/Desktop/CAP/delivery_cost_data (1).xlsx")
```


```{r}

#clean the address data
# Split the column
AddressZipData <- AddressZipData |>
  separate(full.address, into = c("ZIP", "City", "State Name", "State Short", 
                                  "County","Code", "Latitude", "Longitude"), sep = ",")

AddressZipData$Latitude <- as.numeric(AddressZipData$Latitude)

AddressZipData$Longitude <- as.numeric(AddressZipData$Longitude)

# Make sure transaction date is a date
TransactionalData <- TransactionalData |>
  mutate(TRANSACTION_DATE = as.Date(TRANSACTION_DATE))

# Create total volume (gallons + cases)
TransactionalData <- TransactionalData |>
  mutate(
    total_volume = ORDERED_GALLONS + ORDERED_CASES,
    total_delivered = DELIVERED_GALLONS + DELIVERED_CASES,
    prop_delivered = total_delivered/total_volume)

# Aggregate by customer_id and year
annual_volumes <- TransactionalData |>
  group_by(CUSTOMER_NUMBER, YEAR) |>
  summarise(
    total_gallons = sum(ORDERED_GALLONS),
    total_cases = sum(ORDERED_CASES),
    total_volume = sum(total_volume),
    total_delivered = sum(total_delivered),
    prop_delivered = total_delivered/total_volume,
    .groups = "drop")

head(annual_volumes)

volumes_wide <- annual_volumes |>
  pivot_wider(
    names_from = YEAR,
    values_from = c(total_gallons, total_cases, total_volume, total_delivered, prop_delivered),
    names_glue = "{.value}_{YEAR}"
  )

glimpse(volumes_wide)

customer_full <- volumes_wide |>
  left_join(CustomerProfileData, by = "CUSTOMER_NUMBER")

CustomerProfile_Location <- CustomerProfileData %>% 
  left_join(AddressZipData, by = c("ZIP_CODE"="zip")) 

```

* do KMeans clustering to identify the four main location clusters
* identify the center (Centroid) of each of the four main clusters
```{r}
#cluster the addresses and calculate the centroid for each cluster
##Multiple centroids
set.seed(123)

kmeans_result <- kmeans(CustomerProfile_Location[,c("Longitude", "Latitude")], centers = 4)

CustomerProfile_Location$cluster <- as.factor(kmeans_result$cluster)


centroids <- CustomerProfile_Location %>% 
  group_by(cluster) %>% 
  summarize(centroid_lon = mean(Longitude), centroid_lat = mean(Latitude))

haversine_distance <- function(lon1, lat1, lon2, lat2) {
  distHaversine(c(lon1, lat1), c(lon2,lat2))/1609.34 
}# converts meters to miles

#Join main customer data to the clusters created above
CustomerProfile_Location <- CustomerProfile_Location %>% 
  left_join(centroids, by = "cluster")


CustomerProfile_Location <- CustomerProfile_Location %>% 
  mutate(
    distance_to_centroid = mapply(haversine_distance, CustomerProfile_Location$Longitude, CustomerProfile_Location$Latitude, CustomerProfile_Location$centroid_lon, CustomerProfile_Location$centroid_lat)
  )

str(customer_full$CUSTOMER_NUMBER)
str(CustomerProfile_Location$CUSTOMER_NUMBER)

cluster_info <- CustomerProfile_Location |>
  select(CUSTOMER_NUMBER, cluster, distance_to_centroid)

customer_full <- customer_full |>
  left_join(cluster_info, by = "CUSTOMER_NUMBER")



```


I want to use multi level modeling and understand the impact being a retailer vs not has as well as LMP status, Co2, clusters things like that. 

I needed to start first with a larger data source, that is the customer level, order totals for 23 and 24, with parent indicators, but not summated at the parent level, 

now i need to create two columns, part of outlet, and size of retialer to use in mlm


```{r}
customer_full <- customer_full |>
  mutate(
    LOCAL_MARKET_PARTNER = as.factor(LOCAL_MARKET_PARTNER),
    CO2_CUSTOMER = as.factor(CO2_CUSTOMER)
  )

# retailer size
group_size <- customer_full |>
  filter(!is.na(PRIMARY_GROUP_NUMBER)) |>
  group_by(PRIMARY_GROUP_NUMBER) |>
  summarise(retailer_size = n_distinct(CUSTOMER_NUMBER), .groups = "drop")

customer_full <- customer_full |>
  left_join(group_size, by = "PRIMARY_GROUP_NUMBER")

```


```{r}

customer_full |>
  mutate(
    missing_2023 = is.na(total_volume_2023),
    missing_2024 = is.na(total_volume_2024)
  ) %>%
  count(missing_2023, missing_2024)


customer_full <- customer_full |>
  mutate(
    total_volume_2023 = replace_na(total_volume_2023, 0),
    total_volume_2024 = replace_na(total_volume_2024, 0),
    total_gallons_2023 = replace_na(total_gallons_2023, 0),
    total_gallons_2024 = replace_na(total_gallons_2024, 0),
    total_cases_2023 = replace_na(total_cases_2023, 0),
    total_cases_2024 = replace_na(total_cases_2024, 0),
    total_delivered_2023 = replace_na(total_delivered_2023, 0),
    total_delivered_2024 = replace_na(total_delivered_2024, 0),
    prop_delivered_2023 = ifelse(total_volume_2023 == 0, 0, total_delivered_2023 / total_volume_2023),
    prop_delivered_2024 = ifelse(total_volume_2024 == 0, 0, total_delivered_2024 / total_volume_2024),
    volume_change = total_volume_2024 - total_volume_2023
  )




summary(customer_full$volume_change)
hist(customer_full$volume_change, breaks = 50)

colSums(is.na(customer_full))

colnames(customer_full)


customer_full <- customer_full |>
  mutate(
    propCases = (total_cases_2023 + total_cases_2024) / 
                (total_cases_2023 + total_cases_2024 + total_gallons_2023 + total_gallons_2024),
    hasOrderedCases = if_else(total_cases_2023 > 0 | total_cases_2024 > 0, 1, 0)
  )

customer_full <- customer_full |>
  mutate(
    total_ordered_2023 = total_volume_2023 ,
    total_ordered_2024 = total_volume_2024,
    percentChangeYOY = (volume_change) / total_ordered_2023)


# some customers a part of retailers have weird situations where order amounts are 0 
customer_full <- customer_full |>
  mutate(percentChangeYOY = if_else(total_ordered_2023 == 0 & total_ordered_2024 == 0, 0, percentChangeYOY))

str(customer_full)

# fixing YoY infinite issues. 

customer_full <- customer_full |>
  mutate(
    total_ordered_2023_adj = ifelse(total_ordered_2023 == 0 & total_ordered_2024 > 0, 1, total_ordered_2023),
    percentChangeYOY = (total_ordered_2024 - total_ordered_2023_adj) / total_ordered_2023_adj
  )

# fixing the issue for customers who were on boarded in 23 and 24 and are showing super high YoY values 

# using smoothed percentage change maybe should have explored a log diff order value instead of YoY change but oh well. 

customer_full <- customer_full |>
  mutate(
    percentChangeYOY = ifelse(
      total_ordered_2023 == 0 & total_ordered_2024 > 0,
      log1p(total_ordered_2024),  # smooth log growth
      percentChangeYOY            # leave everything else as-is
    )
  )


customer_full <- customer_full |>
  mutate(
    percentChangeYOY = case_when(total_ordered_2023 == 0 & total_ordered_2024 == 0 ~ 0,TRUE ~ percentChangeYOY
    )
  )


customer_full <- customer_full |>
  mutate(
    Binning_column = case_when(
      total_ordered_2023 < 400 & total_ordered_2024 < 400 & percentChangeYOY <= 0.10 ~ "low volume low growth",
      total_ordered_2023 < 400 & total_ordered_2024 < 400 & percentChangeYOY > 0.10 ~ "low volume high growth",
      total_ordered_2023 > 400 & total_ordered_2024 > 400 & percentChangeYOY < 0.05 ~ "high volume low growth",
      total_ordered_2023 > 400 & total_ordered_2024 > 400 & percentChangeYOY > 0.05 ~ "high volume high growth",
      (total_ordered_2023 >= 400 | total_ordered_2024 >= 400) & percentChangeYOY >= 0 ~ "transitionary growing",
      (total_ordered_2023 >= 400 | total_ordered_2024 >= 400) & percentChangeYOY < 0 ~ "transitionary declining",
      TRUE ~ "unclassified"
    )
  )


# set retailer and non retailer data. 

retailer_set <- customer_full |>
  filter(!is.na(PRIMARY_GROUP_NUMBER))

non_retailer_set <- customer_full |>
  filter(is.na(PRIMARY_GROUP_NUMBER))

colnames(retailer_set)


str(retailer_set)

library(lubridate)

retailer_set <- retailer_set |>
  mutate(
    ON_BOARDING_DATE = mdy(ON_BOARDING_DATE),           # convert from "8/5/2015" style to Date
    onboarding_year = year(ON_BOARDING_DATE),           # extract year
    customer_age = 2025 - onboarding_year               # calculate age relative to 2025
  )

```

```{r}


# linear mlm one

str(retailer_set)


retailer_set <- retailer_set |>
  mutate(
    PRIMARY_GROUP_NUMBER = as.factor(PRIMARY_GROUP_NUMBER),
    FREQUENT_ORDER_TYPE = as.factor(FREQUENT_ORDER_TYPE),
    Binning_column = as.factor(Binning_column),
    LOCAL_MARKET_PARTNER = as.factor(LOCAL_MARKET_PARTNER),
    CO2_CUSTOMER = as.factor(CO2_CUSTOMER),
    cluster = as.factor(cluster)
  )

# remove customers from the modeling who are the only ones in thier retail groups. 
retailer_set <- retailer_set |>
  mutate(is_retailer_group = if_else(retailer_size > 1, TRUE, FALSE, missing = FALSE))



mlm_one <- lmer(
  total_ordered_2024 ~ total_ordered_2023 + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER +  percentChangeYOY + distance_to_centroid + propCases +
    (1 | PRIMARY_GROUP_NUMBER), 
  data = retailer_set
)



summary(mlm_one)

summary(mlm_one)
r2(mlm_one)

ranef(mlm_one)$PRIMARY_GROUP_NUMBER %>% head()

```


```{r}
# mlm two only using binning 


mlm_two <- lmer(
  total_ordered_2024 ~ total_ordered_2023 + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER + percentChangeYOY + 
    distance_to_centroid + propCases + 
    (1 | Binning_column),
  data = retailer_set
)

summary(mlm_two)
r2(mlm_two)

ranef(mlm_two)$Binning_column %>% head()



```

```{r}
# mlm three! 

mlm_three <- lmer(
  total_ordered_2024 ~ total_ordered_2023 + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER + percentChangeYOY + 
    distance_to_centroid + propCases  +
    (1 | PRIMARY_GROUP_NUMBER) + (1 | Binning_column),
  data = retailer_set
)


summary(mlm_three)
performance::r2(mlm_three)


ranef(mlm_three)$PRIMARY_GROUP_NUMBER %>% head()
ranef(mlm_three)$Binning_column %>% arrange(desc(`(Intercept)`))


summary(mlm_three)

```

```{r}
# Get model fits
fitted_pg   <- fitted(mlm_one)
fitted_bin  <- fitted(mlm_two)
fitted_both <- fitted(mlm_three)

# Get actuals (same across all models)
actuals <- retailer_set$total_ordered_2024

# Calculate RMSE manually for each model
rmse_pg   <- sqrt(mean((actuals - fitted_pg)^2))
rmse_bin  <- sqrt(mean((actuals - fitted_bin)^2))
rmse_both <- sqrt(mean((actuals - fitted_both)^2))

# Create comparison table
model_comparison <- tribble(
  ~model,                       ~AIC,                  ~marginal_R2,                 ~conditional_R2,               ~RMSE,
  "MLM 1: Primary Group",       AIC(mlm_one),          r2(mlm_one)$R2_marginal,      r2(mlm_one)$R2_conditional,    rmse_pg,
  "MLM 2: Binning Column",      AIC(mlm_two),          r2(mlm_two)$R2_marginal,      r2(mlm_two)$R2_conditional,    rmse_bin,
  "MLM 3: Both Random Effects", AIC(mlm_three),        r2(mlm_three)$R2_marginal,    r2(mlm_three)$R2_conditional,  rmse_both
)

# View it
model_comparison
```

marginal_R2	R² for fixed effects only — how much variance is explained by your predictors
conditional_R2	R² for fixed + random effects — total variance explained by the full model


```{r}

mlm_one_train <- lmer(
  total_ordered_2024 ~ total_ordered_2023 + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER +  percentChangeYOY + distance_to_centroid + propCases +
    (1 | PRIMARY_GROUP_NUMBER), 
  data = train_data
)

mlm_two_train <-lmer(
  total_ordered_2024 ~ total_ordered_2023 + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER + percentChangeYOY + 
    distance_to_centroid + propCases + 
    (1 | Binning_column),
  data = train_data
)

test_data <- test_data |>
  mutate(
    pred_mlm_1 = pmax(predict(mlm_one_train, newdata = test_data, allow.new.levels = TRUE), 0),
    pred_mlm_2 = pmax(predict(mlm_two_train, newdata = test_data, allow.new.levels = TRUE), 0),
    pred_mlm_3 = pmax(predict(mlm_three_train, newdata = test_data, allow.new.levels = TRUE), 0)
  )

test_data_filtered <- test_data |>
  filter(pred_mlm_3 < 100000, total_ordered_2024 < 100000)


# Reshape data for ggplot
long_preds <- test_data_filtered |>
  select(total_ordered_2024, pred_mlm_1, pred_mlm_2, pred_mlm_3) |>
  pivot_longer(cols = starts_with("pred_"), names_to = "model", values_to = "prediction")

# Relabel for nicer legend
long_preds$model <- recode(long_preds$model,
  pred_mlm_1 = "MLM 1 (Primary Group)",
  pred_mlm_2 = "MLM 2 (Binning)",
  pred_mlm_3 = "MLM 3 (Both)"
)

```


```{r}
## presentation actual vs predicted: 

set.seed(123)  # For reproducibility

# 1. Split 80/20
n <- nrow(retailer_set)
train_indices <- sample(seq_len(n), size = 0.8 * n)

train_data <- retailer_set[train_indices, ]
test_data  <- retailer_set[-train_indices, ]

# 2. Fit MLM model on training data
mlm_three_train <- lmer(
  total_ordered_2024 ~ total_ordered_2023 + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER + percentChangeYOY + 
    distance_to_centroid + propCases +
    (1 | PRIMARY_GROUP_NUMBER) + (1 | Binning_column),
  data = train_data
)


test_data <- test_data |>
  mutate(predicted_2024 = pmax(predict(mlm_three_train, newdata = test_data, allow.new.levels = TRUE), 0
 ))


ggplot(test_data, aes(x = total_ordered_2024, y = predicted_2024)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "darkgreen") +
  labs(
    x = "Actuals",
    y = "Predicted" ) +
  theme_minimal()



test_data_filtered <- test_data |>
  filter(predicted_2024 < 100000)



actual_vs_predicted_2024.png <- ggplot(test_data_filtered, aes(x = total_ordered_2024, y = predicted_2024)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(x = "Actual", y = "Predicted") +
  scale_y_continuous(labels = label_number(scale = 1e-3, suffix = "K"))+
  scale_x_continuous(labels = label_number(scale = 1e-3, suffix = "K"))+
  theme_minimal()+
   theme( 
    panel.grid = element_blank(), 
    axis.line = element_line(color = "black"),
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA)) 


ggsave("actual_vs_predicted_2024.png", plot = actual_vs_predicted_2024.png, width = 8, height = 6, dpi = 300)




```


cross validation:
```{r}


# scale for model improvment

retailer_set <- retailer_set |>
  mutate(
    total_ordered_2023_scaled = scale(total_ordered_2023)
  )

mlm_three <- lmer(
  total_ordered_2024 ~ total_ordered_2023_scaled + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER + percentChangeYOY + 
    distance_to_centroid + propCases +
    (1 | PRIMARY_GROUP_NUMBER) + (1 | Binning_column),
  data = retailer_set
)

summary(mlm_three)

# cross validtation

set.seed(123)  # Reproducibility

# Fold assignment by retailer group
group_folds <- retailer_set |>
  distinct(PRIMARY_GROUP_NUMBER) |>
  mutate(fold = sample(rep(1:5, length.out = n())))

retailer_set_cv <- retailer_set |>
  left_join(group_folds, by = "PRIMARY_GROUP_NUMBER")

# Cross-validation loop
cv_results <- map_df(1:5, function(fold_num) {
  
  # Train/test split
  train_data <- retailer_set_cv |>
    filter(fold != fold_num)
  test_data  <- retailer_set_cv |>
    filter(fold == fold_num)
  
  # Fit MLM
  model <- lmer(
    total_ordered_2024 ~ total_ordered_2023_scaled + FREQUENT_ORDER_TYPE +
      LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER + percentChangeYOY +
      distance_to_centroid + propCases  +
      (1 | PRIMARY_GROUP_NUMBER) + (1 | Binning_column),
    data = train_data
  )
  
  # Predict on test
  preds <- predict(model, newdata = test_data, allow.new.levels = TRUE)
  
  # Calculate metrics
  rmse_val <- rmse_vec(test_data$total_ordered_2024, preds)
  r2_vals  <- performance::r2(model)
  
  tibble(
    fold = fold_num,
    rmse = rmse_val,
    marginal_r2 = r2_vals$R2_marginal,
    conditional_r2 = r2_vals$R2_conditional
  )
})

# Summary across folds
cv_results_summary <- cv_results |>
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse = sd(rmse),
    mean_marginal_r2 = mean(marginal_r2),
    mean_conditional_r2 = mean(conditional_r2)
  )

# View
print(cv_results)
print(cv_results_summary)

```


Compared to Before (Full Model):
Your earlier full model (no CV) had:

RMSE around 11,648

Marginal R² ~0.879

Conditional R² ~0.990

So:

Cross-validated performance is very strong, and actually more reassuring — most folds beat the full-model RMSE, and R² is consistently high.

Variability in RMSE across folds is something to keep an eye on, but not a dealbreaker.


predictions:

```{r}

mlm_three <- lmer(
  total_ordered_2024 ~ total_ordered_2023 + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER + percentChangeYOY + 
    distance_to_centroid + propCases +
    (1 | PRIMARY_GROUP_NUMBER) + (1 | Binning_column),
  data = retailer_set
)


retailer_set <- retailer_set |>
  group_by(PRIMARY_GROUP_NUMBER) |>
  mutate(retailer_size = n()) |>
  ungroup()



mlm_three_half <- lmer(
  total_ordered_2024 ~ total_ordered_2023 + FREQUENT_ORDER_TYPE + 
    LOCAL_MARKET_PARTNER + customer_age + CO2_CUSTOMER + percentChangeYOY + 
    distance_to_centroid + propCases + retailer_size +
    (1 | PRIMARY_GROUP_NUMBER) + (1 | Binning_column),
  data = retailer_set
)

summary(mlm_three_half)

predict_2025_data <- retailer_set |>
  mutate(
    total_ordered_2023 = total_ordered_2024,      
    customer_age = customer_age + 1              
  ) %>%
  select(-total_ordered_2024)                      

predicted_2025 <- predict(mlm_three, newdata = predict_2025_data, allow.new.levels = TRUE)

predict_2025_data <- predict_2025_data %>%
  mutate(predicted_total_ordered_2025 = predicted_2025)

# ercentChangeYoY now that we have predictions
predict_2025_data <- predict_2025_data |>
  mutate(
    percentChangeYoY = (predicted_total_ordered_2025 - total_ordered_2023) / total_ordered_2023
  )


```
insights:

```{r}

predict_2025_data <- predict_2025_data |>
  mutate(
    grew_2024 = total_ordered_2023 > 400,
    predicted_grow_2025 = predicted_total_ordered_2025 > 400)

predict_2025_data <- predict_2025_data |>
  mutate(
    grew_2024 = total_ordered_2023 > 400,
    predicted_grow_2025 = predicted_total_ordered_2025 > 400
  )


# Filter for new growers: not over 400 in 2024, but predicted to be in 2025
emerging_2025_growers <- predict_2025_data %>%
  filter(!grew_2024 & predicted_grow_2025)



# Summary: how many?
nrow(emerging_2025_growers)


# % of all customers that are projected to newly grow
nrow(emerging_2025_growers) / nrow(predict_2025_data)

# Average predicted volume of new growers
mean(emerging_2025_growers$predicted_total_ordered_2025)

mean(emerging_2025_growers$total_ordered_2023)


# Distribution
ggplot(emerging_2025_growers, aes(x = predicted_total_ordered_2025)) +
  geom_histogram(bins = 30) +
  labs(title = "Predicted Volume for New 2025 Growers")


(44 * 411) + (519 * 535)

```
